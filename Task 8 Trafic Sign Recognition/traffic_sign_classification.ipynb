{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27ff535d",
   "metadata": {},
   "source": [
    "# Traffic Sign Classification â€” GTSRB\n",
    "\n",
    "> Jupyter Notebook to classify German Traffic Signs (GTSRB) using a custom CNN and transfer learning (MobileNetV2). Designed to run on a local CUDA-enabled laptop.\n",
    "\n",
    "**What you'll get:** dataset loading, preprocessing, augmentation, custom CNN training, evaluation (accuracy + confusion matrix), and a MobileNetV2 transfer-learning comparison.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick instructions:**\n",
    "- Update `DATA_ROOT` to point to your extracted Kaggle dataset. The notebook expects folders like `Final_Training/Images` within that root.\n",
    "- Make sure you have a TensorFlow GPU build installed compatible with your CUDA/CuDNN.\n",
    "- Run cells in order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1738a3fc",
   "metadata": {},
   "source": [
    "## 1. Imports & GPU check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports and GPU check\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('GPUs found:', gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24916b6",
   "metadata": {},
   "source": [
    "## 2. Paths / Dataset structure\n",
    "Adjust these paths to where you extracted your Kaggle dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478d7ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this path to where you extracted the Kaggle GTSRB dataset\n",
    "DATA_ROOT = './gtsrb'  # change to your dataset root\n",
    "TRAIN_DIR = os.path.join(DATA_ROOT, 'Final_Training', 'Images')\n",
    "TEST_DIR = os.path.join(DATA_ROOT, 'Final_Test', 'Images')\n",
    "\n",
    "print('Train dir exists?', os.path.exists(TRAIN_DIR))\n",
    "print('Test dir exists?', os.path.exists(TEST_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafcd68b",
   "metadata": {},
   "source": [
    "## 3. Load dataset (resizing + split)\n",
    "We'll use image_dataset_from_directory and split a validation set from training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a34bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = (64, 64)\n",
    "VAL_SPLIT = 0.15\n",
    "SEED = 123\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    validation_split=VAL_SPLIT,\n",
    "    subset='training',\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='int'\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    validation_split=VAL_SPLIT,\n",
    "    subset='validation',\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='int'\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "NUM_CLASSES = len(class_names)\n",
    "print('Found classes:', NUM_CLASSES)\n",
    "print('Class names (first 10):', class_names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e15700",
   "metadata": {},
   "source": [
    "## 4. Prefetch, Caching, and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c70f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Show a batch sample\n",
    "for images, labels in train_ds.take(1):\n",
    "    print('Batch image shape:', images.shape)\n",
    "    print('Batch labels shape:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0741c6d2",
   "metadata": {},
   "source": [
    "## 5. Data Augmentation\n",
    "We'll build a simple augmentation pipeline and visualize samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e31d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.08),\n",
    "    layers.RandomZoom(0.08),\n",
    "    layers.RandomTranslation(0.05, 0.05)\n",
    "], name='data_augmentation')\n",
    "\n",
    "# Visualize augmentation example\n",
    "for images, labels in train_ds.take(1):\n",
    "    plt.figure(figsize=(9,9))\n",
    "    augmented = data_augmentation(images)\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3,3,i+1)\n",
    "        plt.imshow(augmented[i].numpy())\n",
    "        plt.axis('off')\n",
    "    plt.suptitle('Augmented samples')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60bb311",
   "metadata": {},
   "source": [
    "## 6. Custom CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c2cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_custom_cnn(input_shape=(64,64,3), num_classes=NUM_CLASSES):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = data_augmentation(inputs)\n",
    "    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs, name='custom_cnn')\n",
    "    return model\n",
    "\n",
    "model = make_custom_cnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c42bdb6",
   "metadata": {},
   "source": [
    "## 7. Compile and Train (Custom CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd4d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('best_custom_cnn.h5', save_best_only=True, monitor='val_accuracy'),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=6, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bca0a2",
   "metadata": {},
   "source": [
    "## 8. Evaluate & Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047e5be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    fig, axes = plt.subplots(1,2, figsize=(14,4))\n",
    "    axes[0].plot(history.history['loss'], label='train_loss')\n",
    "    axes[0].plot(history.history['val_loss'], label='val_loss')\n",
    "    axes[0].legend(); axes[0].set_title('Loss')\n",
    "\n",
    "    axes[1].plot(history.history['accuracy'], label='train_acc')\n",
    "    axes[1].plot(history.history['val_accuracy'], label='val_acc')\n",
    "    axes[1].legend(); axes[1].set_title('Accuracy')\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b6bee3",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrix & Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebbd239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect labels and predictions on the validation set\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in val_ds:\n",
    "    preds = model.predict(images)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(12,10))\n",
    "cm_norm = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 1e-9)\n",
    "sns.heatmap(cm_norm, annot=False, cmap='viridis')\n",
    "plt.title('Normalized Confusion Matrix (validation)')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c137bca",
   "metadata": {},
   "source": [
    "## 10. Bonus: Transfer Learning with MobileNetV2\n",
    "We'll prepare datasets at a larger size and train a MobileNetV2 head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db06996",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE_TL = (96, 96)\n",
    "BATCH_SIZE_TL = 32\n",
    "\n",
    "train_ds_tl = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    validation_split=VAL_SPLIT,\n",
    "    subset='training',\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE_TL,\n",
    "    batch_size=BATCH_SIZE_TL,\n",
    "    label_mode='int'\n",
    ")\n",
    "val_ds_tl = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    validation_split=VAL_SPLIT,\n",
    "    subset='validation',\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE_TL,\n",
    "    batch_size=BATCH_SIZE_TL,\n",
    "    label_mode='int'\n",
    ")\n",
    "\n",
    "train_ds_tl = train_ds_tl.map(lambda x, y: (tf.cast(x, tf.float32)/255.0, y)).cache().prefetch(AUTOTUNE)\n",
    "val_ds_tl = val_ds_tl.map(lambda x, y: (tf.cast(x, tf.float32)/255.0, y)).cache().prefetch(AUTOTUNE)\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SIZE_TL + (3,), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = keras.Input(shape=IMG_SIZE_TL + (3,))\n",
    "x = data_augmentation(inputs)\n",
    "x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model_tl = keras.Model(inputs, outputs, name='mobilenetv2_tl')\n",
    "model_tl.compile(optimizer=keras.optimizers.Adam(1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_tl.summary()\n",
    "\n",
    "callbacks_tl = [keras.callbacks.ModelCheckpoint('best_mobilenetv2.h5', save_best_only=True, monitor='val_accuracy'),\n",
    "                keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)]\n",
    "\n",
    "history_tl = model_tl.fit(train_ds_tl, validation_data=val_ds_tl, epochs=12, callbacks=callbacks_tl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135e134b",
   "metadata": {},
   "source": [
    "### Fine-tuning (optional)\n",
    "Unfreeze top layers and fine-tune with a lower learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example fine-tune\n",
    "base_model.trainable = True\n",
    "fine_tune_at = 100\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_tl.compile(optimizer=keras.optimizers.Adam(1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_ft = model_tl.fit(train_ds_tl, validation_data=val_ds_tl, epochs=8, callbacks=callbacks_tl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46fccad",
   "metadata": {},
   "source": [
    "## 11. Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8868c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Custom CNN best val_acc:', max(history.history['val_accuracy'])))\n",
    "print('MobileNetV2 best val_acc:', max(history_tl.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdee7f9f",
   "metadata": {},
   "source": [
    "## 12. Save models & tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be35b7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final models\n",
    "model.save('final_custom_cnn_saved')\n",
    "model_tl.save('final_mobilenetv2_saved')\n",
    "\n",
    "print('Models saved to disk.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
